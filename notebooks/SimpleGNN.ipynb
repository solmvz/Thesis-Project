{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tC7K1h5RJGPi"
      },
      "source": [
        "# Upload Preliminaries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "TPyHncOK7vLo"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"DGLBACKEND\"] = \"pytorch\"\n",
        "import dgl\n",
        "import dgl.data\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "import torch\n",
        "#import torch_geometric\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "#from torch_geometric.nn import GATConv\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "tKYrZYqb6bu2"
      },
      "outputs": [],
      "source": [
        "# Tensorboard\n",
        "from torch.utils.tensorboard import SummaryWriter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "y2qz--p8oHTq"
      },
      "outputs": [],
      "source": [
        "from dgl.data import CoraGraphDataset\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "def load_cora_data():\n",
        "    dataset = CoraGraphDataset()\n",
        "    num_classes = dataset.num_classes\n",
        "    g = dataset[0]\n",
        "    scaler = MinMaxScaler()\n",
        "    features = torch.tensor(scaler.fit_transform(g.ndata[\"feat\"]), dtype=torch.float)\n",
        "    labels = g.ndata[\"label\"]\n",
        "    train_mask = g.ndata[\"train_mask\"]\n",
        "    test_mask = g.ndata[\"test_mask\"]\n",
        "    return g, features, labels, num_classes, train_mask, test_mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "i6b508ZMzgSX"
      },
      "outputs": [],
      "source": [
        "def create_line_graphs(G, t_levels):\n",
        "  line_graphs = []\n",
        "  features = []\n",
        "  B = []\n",
        "  current_g = G\n",
        "  num_feats = G.ndata['feat'].shape[1]\n",
        "  line_graphs.append(G)\n",
        "  features.append(G.ndata['feat'])\n",
        "  B.append(g.inc('in').to_dense())\n",
        "  for t in range(1, t_levels):\n",
        "    lg = current_g.line_graph(backtracking=True)\n",
        "    line_graphs.append(lg)\n",
        "    features.append(torch.zeros((lg.num_nodes(), num_feats)))\n",
        "    B.append(lg.inc('in').to_dense())\n",
        "    current_g = lg\n",
        "  return line_graphs, features, B"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "ol4LGYSIoMCq"
      },
      "outputs": [],
      "source": [
        "def evaluate(train_logits, model, g, features, labels, train_mask, test_mask):\n",
        "    tr_logits = train_logits[train_mask]\n",
        "    tr_label = labels[train_mask]\n",
        "    _, indices = torch.max(train_logits, dim=1)\n",
        "    correct = torch.sum(indices == labels)\n",
        "    train_acc = correct.item() * 1.0 / len(labels)\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        test_logits = model(g, features)\n",
        "        test_logits = test_logits[test_mask]\n",
        "        labels = labels[test_mask]\n",
        "        _, indices = torch.max(test_logits, dim=1)\n",
        "        correct = torch.sum(indices == labels)\n",
        "        test_acc = correct.item() * 1.0 / len(labels)\n",
        "    return train_acc, test_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ByW8xuTfNBg0",
        "outputId": "2c066152-60cf-4bc4-8b97-b13cb633c5a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  NumNodes: 2708\n",
            "  NumEdges: 10556\n",
            "  NumFeats: 1433\n",
            "  NumClasses: 7\n",
            "  NumTrainingSamples: 140\n",
            "  NumValidationSamples: 500\n",
            "  NumTestSamples: 1000\n",
            "Done loading data from cached files.\n"
          ]
        }
      ],
      "source": [
        "g, features, labels, num_classes, train_mask, test_mask = load_cora_data()\n",
        "\n",
        "line_graphs_list, features_list, Incident_Matrix = create_line_graphs(g, 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-9asAP1aJVm5"
      },
      "source": [
        "# Design the network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "k3VHa0d63sRq"
      },
      "outputs": [],
      "source": [
        "from dgl.nn import GraphConv\n",
        "\n",
        "class Net2(nn.Module):\n",
        "  def __init__(self, in_feats, out_feats):\n",
        "    super(Net2, self).__init__()\n",
        "    self.fusion = nn.Linear(in_feats, out_feats)\n",
        "  def forward(self, h_t, B, t):\n",
        "    B_star = B[0]\n",
        "    for matrix in B[1:t]:\n",
        "      B_star = torch.matmul(B_star, matrix)\n",
        "    mask = B_star != 0\n",
        "    B_star[mask] = 1\n",
        "    b_t = torch.matmul(B_star, h_t)\n",
        "    return b_t"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "jW9XGxRTHNKX"
      },
      "outputs": [],
      "source": [
        "from dgl.nn import GraphConv\n",
        "\n",
        "\n",
        "class HGNNLayer(nn.Module):\n",
        "  def __init__(self, in_feats, out_feats):\n",
        "    super(HGNNLayer, self).__init__()\n",
        "    self.conv = GraphConv(in_feats, out_feats)\n",
        "    self.fuse = nn.Linear(out_feats, out_feats)\n",
        "\n",
        "  def forward(self, g_t, f_t, B, prev_f, t):\n",
        "    h_t = self.conv(g_t, f_t)\n",
        "    B_T = torch.transpose(B, 0, 1)\n",
        "    a_t = torch.mm(B_T, prev)\n",
        "    a_t = self.fuse(a_t)\n",
        "    h_t = h_t + a_t\n",
        "    return F.relu(h_t)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "VVpczVKfILxa"
      },
      "outputs": [],
      "source": [
        "class HGNN(nn.Module):\n",
        "  def __init__(self, in_feats, h_feats):\n",
        "    super(HGNN, self).__init__()\n",
        "    self.conv = GraphConv(in_feats, h_feats)\n",
        "    self.hgnn = HGNNLayer(in_feats, h_feats)\n",
        "    self.net2 = Net2(h_feats, h_feats)\n",
        "    self.combine = nn.Linear(h_feats, h_feats)\n",
        "\n",
        "  def forward(self, G, f, B):\n",
        "    h = []\n",
        "    embeddings = []\n",
        "\n",
        "    h_0 = F.relu(self.conv(G[0], f[0]))\n",
        "    h.append(h_0)\n",
        "    embeddings.append(h_0)\n",
        "\n",
        "    for t in range(1, len(G)):\n",
        "      h_t = self.hgnn(G[t], f[t], B[t-1], f[t-1], t)\n",
        "      h.append(h_t)\n",
        "      embeddings.append(self.net2(h_t, B, t))\n",
        "\n",
        "    concatenated_embeddings = torch.cat(embeddings, dim=0)\n",
        "\n",
        "    f_star = torch.mean(torch.stack(embeddings), dim=0)\n",
        "\n",
        "    h[0] = f_star\n",
        "\n",
        "    return h\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "Y7ywV5yQJJH9"
      },
      "outputs": [],
      "source": [
        "class StackLayers(nn.Module):\n",
        "  def __init__(self, in_feats, num_classes):\n",
        "    super(StackLayers, self).__init__()\n",
        "    self.hidden_layer1 = HGNN(in_feats, 16)\n",
        "    self.output_layer = HGNN(16, num_classes)\n",
        "\n",
        "  def forward(self, g, f, B):\n",
        "    h1 = self.hidden_layer1(g, f, B)\n",
        "    z = self.output_layer(g, h1, B)\n",
        "    return z[0]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42PXKyoYJjC5"
      },
      "source": [
        "# Train and Evaluate the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cUke_gMV7QAW"
      },
      "outputs": [],
      "source": [
        "model = StackLayers(features.shape[1], num_classes)\n",
        "\n",
        "print(\"the model\")\n",
        "print(model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "uWIHEgx_oR8c",
        "outputId": "0ee11755-4f47-4005-f585-7a3af3e2a4a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "h_t torch.Size([10556, 16])\n",
            "prev, torch.Size([2708, 16])\n",
            "B_T torch.Size([10556, 2708])\n",
            "final h_t torch.Size([10556, 16])\n",
            "t is  1\n",
            "B*:  torch.Size([2708, 10556])\n",
            "b_t:  torch.Size([2708, 16])\n",
            "h_t torch.Size([10556, 7])\n",
            "prev, torch.Size([2708, 7])\n",
            "B_T torch.Size([10556, 2708])\n",
            "final h_t torch.Size([10556, 7])\n",
            "t is  1\n",
            "B*:  torch.Size([2708, 10556])\n",
            "b_t:  torch.Size([2708, 7])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\solma\\anaconda3\\Lib\\site-packages\\torch\\autograd\\__init__.py:266: UserWarning: Error detected in MmBackward0. Traceback of forward call that caused the error:\n",
            "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
            "  File \"<frozen runpy>\", line 88, in _run_code\n",
            "  File \"c:\\Users\\solma\\anaconda3\\Lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n",
            "    app.launch_new_instance()\n",
            "  File \"c:\\Users\\solma\\anaconda3\\Lib\\site-packages\\traitlets\\config\\application.py\", line 992, in launch_instance\n",
            "    app.start()\n",
            "  File \"c:\\Users\\solma\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 736, in start\n",
            "    self.io_loop.start()\n",
            "  File \"c:\\Users\\solma\\anaconda3\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n",
            "    self.asyncio_loop.run_forever()\n",
            "  File \"c:\\Users\\solma\\anaconda3\\Lib\\asyncio\\base_events.py\", line 607, in run_forever\n",
            "    self._run_once()\n",
            "  File \"c:\\Users\\solma\\anaconda3\\Lib\\asyncio\\base_events.py\", line 1922, in _run_once\n",
            "    handle._run()\n",
            "  File \"c:\\Users\\solma\\anaconda3\\Lib\\asyncio\\events.py\", line 80, in _run\n",
            "    self._context.run(self._callback, *self._args)\n",
            "  File \"c:\\Users\\solma\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 516, in dispatch_queue\n",
            "    await self.process_one()\n",
            "  File \"c:\\Users\\solma\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 505, in process_one\n",
            "    await dispatch(*args)\n",
            "  File \"c:\\Users\\solma\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 412, in dispatch_shell\n",
            "    await result\n",
            "  File \"c:\\Users\\solma\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 740, in execute_request\n",
            "    reply_content = await reply_content\n",
            "  File \"c:\\Users\\solma\\anaconda3\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 422, in do_execute\n",
            "    res = shell.run_cell(\n",
            "  File \"c:\\Users\\solma\\anaconda3\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 546, in run_cell\n",
            "    return super().run_cell(*args, **kwargs)\n",
            "  File \"c:\\Users\\solma\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3024, in run_cell\n",
            "    result = self._run_cell(\n",
            "  File \"c:\\Users\\solma\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3079, in _run_cell\n",
            "    result = runner(coro)\n",
            "  File \"c:\\Users\\solma\\anaconda3\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n",
            "    coro.send(None)\n",
            "  File \"c:\\Users\\solma\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3284, in run_cell_async\n",
            "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
            "  File \"c:\\Users\\solma\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3466, in run_ast_nodes\n",
            "    if await self.run_code(code, result, async_=asy):\n",
            "  File \"c:\\Users\\solma\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3526, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"C:\\Users\\solma\\AppData\\Local\\Temp\\ipykernel_20096\\1982913602.py\", line 19, in <module>\n",
            "    logits = model(line_graphs_list, features_list, Incident_Matrix)\n",
            "  File \"c:\\Users\\solma\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1511, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"c:\\Users\\solma\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1520, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"C:\\Users\\solma\\AppData\\Local\\Temp\\ipykernel_20096\\681235449.py\", line 9, in forward\n",
            "    z = self.output_layer(g, h1, B)\n",
            "  File \"c:\\Users\\solma\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1511, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"c:\\Users\\solma\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1520, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"C:\\Users\\solma\\AppData\\Local\\Temp\\ipykernel_20096\\1408698826.py\", line 18, in forward\n",
            "    h_t = self.hgnn(G[t], f[t], B[t-1], f[t-1], t)\n",
            "  File \"c:\\Users\\solma\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1511, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"c:\\Users\\solma\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1520, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"C:\\Users\\solma\\AppData\\Local\\Temp\\ipykernel_20096\\1576554293.py\", line 18, in forward\n",
            "    a_t = torch.mm(B_T, prev)\n",
            " (Triggered internally at C:\\b\\abs_6fueooay2f\\croot\\pytorch-select_1707342446212\\work\\torch\\csrc\\autograd\\python_anomaly_mode.cpp:118.)\n",
            "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "one of the variables needed for gradient computation has been modified by an inplace operation: [torch.FloatTensor [10556, 2708]] is at version 4; expected version 3 instead. Hint: the backtrace further above shows the operation that failed to compute its gradient. The variable in question was changed in there or anywhere later. Good luck!",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[24], line 24\u001b[0m\n\u001b[0;32m     21\u001b[0m loss \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mnll_loss(logp[train_mask], labels[train_mask])\n\u001b[0;32m     23\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mset_detect_anomaly(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 24\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     25\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m epoch \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m:\n",
            "File \u001b[1;32mc:\\Users\\solma\\anaconda3\\Lib\\site-packages\\torch\\_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    521\u001b[0m     )\n\u001b[1;32m--> 522\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[0;32m    523\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[0;32m    524\u001b[0m )\n",
            "File \u001b[1;32mc:\\Users\\solma\\anaconda3\\Lib\\site-packages\\torch\\autograd\\__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 266\u001b[0m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    267\u001b[0m     tensors,\n\u001b[0;32m    268\u001b[0m     grad_tensors_,\n\u001b[0;32m    269\u001b[0m     retain_graph,\n\u001b[0;32m    270\u001b[0m     create_graph,\n\u001b[0;32m    271\u001b[0m     inputs,\n\u001b[0;32m    272\u001b[0m     allow_unreachable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    273\u001b[0m     accumulate_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    274\u001b[0m )\n",
            "\u001b[1;31mRuntimeError\u001b[0m: one of the variables needed for gradient computation has been modified by an inplace operation: [torch.FloatTensor [10556, 2708]] is at version 4; expected version 3 instead. Hint: the backtrace further above shows the operation that failed to compute its gradient. The variable in question was changed in there or anywhere later. Good luck!"
          ]
        }
      ],
      "source": [
        "import time\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Add edges between each node and itself to preserve old node representations\n",
        "g.add_edges(g.nodes(), g.nodes())\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)\n",
        "dur = []\n",
        "for epoch in range(100):\n",
        "    if epoch >= 3:\n",
        "        t0 = time.time()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "\n",
        "    model.train()\n",
        "    logits = model(line_graphs_list, features_list, Incident_Matrix)\n",
        "    logp = F.log_softmax(logits, 1)\n",
        "    loss = F.nll_loss(logp[train_mask], labels[train_mask])\n",
        "\n",
        "    torch.autograd.set_detect_anomaly(True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "\n",
        "    if epoch >= 3:\n",
        "        dur.append(time.time() - t0)\n",
        "\n",
        "    train_acc, test_acc = evaluate(logits, model, g, features, labels, train_mask, test_mask)\n",
        "    print(\n",
        "        \"Epoch {:05d} | Loss {:.4f} | Train Acc {:.4f} | Test Acc {:.4f} | Time(s) {:.4f}\".format(\n",
        "            epoch, loss.item(), train_acc, test_acc, np.mean(dur)\n",
        "        )\n",
        "    )"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
